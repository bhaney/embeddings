{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multigraph import MultiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading relation 0...\n",
      "loading relation 1...\n",
      "loading relation 2...\n",
      "loading relation 3...\n",
      "loading relation 4...\n",
      "loading relation 5...\n",
      "loading relation 6...\n",
      "loading relation 7...\n",
      "loading relation 8...\n",
      "loading relation 9...\n",
      "loading relation 10...\n",
      "loading relation 11...\n",
      "loading relation 12...\n",
      "loading relation 13...\n",
      "loading relation 14...\n",
      "loading relation 15...\n",
      "loading relation 16...\n",
      "loading relation 17...\n",
      "loading relation 18...\n",
      "loading relation 19...\n",
      "loading relation 20...\n",
      "loading relation 21...\n",
      "loading relation 22...\n",
      "loading relation 23...\n",
      "loading relation 24...\n",
      "loading relation 25...\n",
      "loading relation 26...\n",
      "loading relation 27...\n",
      "loading relation 28...\n",
      "loading relation 29...\n",
      "loading relation 30...\n",
      "loading relation 31...\n",
      "loading relation 32...\n",
      "loading relation 33...\n",
      "loading relation 34...\n",
      "loading relation 35...\n",
      "loading relation 36...\n",
      "loading relation 37...\n",
      "loading relation 38...\n",
      "loading relation 39...\n",
      "loading relation 40...\n",
      "loading relation 41...\n",
      "loading relation 42...\n",
      "loading relation 43...\n",
      "loading relation 44...\n"
     ]
    }
   ],
   "source": [
    "#import csv\n",
    "import unicodecsv as csv\n",
    "\"\"\" EXAMPLE\n",
    "add,IS,operator\n",
    "subtract,IS,operator\n",
    "multiply,IS,operator\n",
    "divide,IS,operator\n",
    "open_closure,IS,operator\n",
    "close_closure,IS,operator\n",
    "\"\"\"\n",
    "op_graph = MultiGraph()\n",
    "#with open('operator_graph.csv', 'r') as csvfile:\n",
    "for i in range(45):\n",
    "    print('loading relation '+str(i)+'...')\n",
    "    with open('aifb_csv/aifb_relation_'+str(i)+'.csv', 'r') as csvfile:\n",
    "        graphreader = csv.reader(csvfile, delimiter=\",\")\n",
    "        for row in graphreader:\n",
    "            #print(row)\n",
    "            op_graph.add_connection(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of nodes', 8284)\n",
      "('number of relations', 45)\n",
      "relations:\n",
      "(u'ontology#number', 145)\n",
      "(u'ontology#isWorkedOnBy', 571)\n",
      "(u'ontology#worksAtProject', 200)\n",
      "(u'owl#allValuesFrom', 152)\n",
      "(u'ontology#dealtWithIn', 357)\n",
      "(u'owl#onProperty', 152)\n",
      "(u'ontology#type', 50)\n",
      "(u'ontology#author', 3986)\n",
      "(u'ontology#abstract', 534)\n",
      "(u'ontology#carriedOutBy', 79)\n",
      "(u'ontology#month', 759)\n",
      "(u'ontology#phone', 227)\n",
      "(u'22-rdf-syntax-ns#type', 4124)\n",
      "(u'ontology#address', 202)\n",
      "(u'ontology#note', 114)\n",
      "(u'ontology#publication', 4163)\n",
      "(u'ontology#financedBy', 65)\n",
      "(u'ontology#chapter', 15)\n",
      "(u'ontology#editor', 190)\n",
      "(u'ontology#pages', 548)\n",
      "(u'owl#inverseOf', 10)\n",
      "(u'ontology#projectInfo', 952)\n",
      "(u'type', 129)\n",
      "(u'ontology#edition', 12)\n",
      "(u'ontology#booktitle', 765)\n",
      "(u'ontology#isAbout', 2477)\n",
      "(u'ontology#finances', 68)\n",
      "(u'ontology#howpublished', 49)\n",
      "(u'ontology#member', 339)\n",
      "(u'ontology#hasProject', 952)\n",
      "(u'ontology#isbn', 16)\n",
      "(u'ontology#journal', 161)\n",
      "(u'ontology#year', 1227)\n",
      "(u'ontology#title', 1227)\n",
      "(u'ontology#fax', 227)\n",
      "(u'rdf-schema#range', 1)\n",
      "(u'ontology#homepage', 239)\n",
      "(u'ontology#carriesOut', 79)\n",
      "(u'ontology#photo', 148)\n",
      "(u'rdf-schema#subClassOf', 199)\n",
      "(u'ontology#head', 5)\n",
      "(u'ontology#volume', 311)\n",
      "(u'ontology#publishes', 1217)\n",
      "(u'ontology#name', 1302)\n",
      "(u'ontology#series', 298)\n"
     ]
    }
   ],
   "source": [
    "a_graph = op_graph.get_adjacency_matrix()\n",
    "print(\"number of nodes\",op_graph.n_nodes)\n",
    "print(\"number of relations\",op_graph.n_rels)\n",
    "print(\"relations:\")\n",
    "for k,v in op_graph.rel_counter.iteritems():\n",
    "    print(k.rsplit('/',1)[-1], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input dims:', (8284, 372780))\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x372780 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 18 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = a_graph\n",
    "print('input dims:',x_train.shape)\n",
    "print(type(x_train))\n",
    "sum(list(x_train[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 128\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "inputs = Input(shape=(input_dim,))\n",
    "# Encoder Layers\n",
    "encoding_1 = Dense(4 * encoding_dim, activation='tanh',name=\"encoding_1\")(inputs)\n",
    "encoding_2 = Dense(2 * encoding_dim, activation='tanh',name=\"encoding_2\")(encoding_1)\n",
    "the_code = Dense(encoding_dim, activation='tanh',name=\"the_code\")(encoding_2)\n",
    "# Decoder Layers\n",
    "decoding_1 = Dense(4 * encoding_dim, activation='tanh',name=\"decoding_1\")(the_code)\n",
    "decoding_2 = Dense(2 * encoding_dim, activation='tanh',name=\"decoding_2\")(decoding_1)\n",
    "reconstruction = Dense(input_dim, activation='tanh',name=\"reconstruction\")(decoding_2)\n",
    "\n",
    "ae = Model(inputs=inputs, outputs=reconstruction)\n",
    "#monitor = EarlyStopping(monitor='loss', min_delta=0.0001, patience=5, verbose=1, mode='auto')\n",
    "ae.compile(optimizer='adam', loss='mse')\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.fit(x_train, x_train.toarray(), epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding_model = Model(inputs=ae.inputs, outputs=ae.get_layer(\"the_code\").output)\n",
    "coding_model = Model(inputs=inputs, outputs=the_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the embeddings in order to plot them later\n",
    "# serialize model to JSON\n",
    "model_json = coding_model.to_json()\n",
    "with open(\"coding_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "coding_model.save_weights(\"coding_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# sample usage\n",
    "save_object(op_graph, 'adj_graph.pkl')\n",
    "print(\"Saved graph object to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
