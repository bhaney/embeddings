{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multigraph import MultiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv\n",
    "import unicodecsv as csv\n",
    "\"\"\" EXAMPLE\n",
    "add,IS,operator\n",
    "subtract,IS,operator\n",
    "multiply,IS,operator\n",
    "divide,IS,operator\n",
    "open_closure,IS,operator\n",
    "close_closure,IS,operator\n",
    "\"\"\"\n",
    "op_graph = MultiGraph()\n",
    "#with open('operator_graph.csv', 'r') as csvfile:\n",
    "n = 45\n",
    "for i in range(n):\n",
    "    print '.',\n",
    "    with open('aifb_csv/aifb_relation_'+str(i)+'.csv', 'r') as csvfile:\n",
    "        graphreader = csv.reader(csvfile, delimiter=\",\")\n",
    "        for row in graphreader:\n",
    "            op_graph.add_connection(row)\n",
    "print('\\n loaded '+str(op_graph.n_rels)+' relations.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_graph = op_graph.get_adjacency_matrix()\n",
    "print(\"number of nodes\",op_graph.n_nodes)\n",
    "print(\"number of relations\",op_graph.n_rels)\n",
    "print(\"relations:\")\n",
    "for k,v in op_graph.rel_counter.iteritems():\n",
    "    print(k.rsplit('/',1)[-1], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = a_graph\n",
    "print('input dims:',x_train.shape)\n",
    "print(type(x_train))\n",
    "sum(list(x_train[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to make a custom Dense layer to tie weights between the encoder and decoder\n",
    "from keras import backend as K\n",
    "\n",
    "class DenseTied(Dense):\n",
    "    def __init__(self, master_layer, **kwargs):\n",
    "        #output_dim needs to be equal to the input dimensions of the master_layer\n",
    "        self.output_dim = master_layer.input_shape[-1]\n",
    "        super(DenseTied, self).__init__(self.output_dim, **kwargs)\n",
    "        self.master_layer = master_layer\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "        assert len(input_shape) >= 2\n",
    "        input_dim = input_shape[-1]\n",
    "\n",
    "        self.kernel = K.transpose(self.master_layer.kernel)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.output_dim,),\n",
    "                            initializer=self.bias_initializer,\n",
    "                            name='bias',\n",
    "                            regularizer=self.bias_regularizer,\n",
    "                            constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        output = K.dot(inputs, K.transpose(self.master_layer.kernel))\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 128\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "inputs = Input(shape=(input_dim,),name=\"inputs\")\n",
    "# Encoder Layers\n",
    "encode_layer1 = Dense(4 * encoding_dim, activation='tanh',name=\"encode_layer1\")\n",
    "encode_layer2 = Dense(2 * encoding_dim, activation='tanh',name=\"encode_layer2\")\n",
    "coding_layer = Dense(encoding_dim, activation='tanh',name=\"coding_layer\")\n",
    "\n",
    "encoding_1 = encode_layer1(inputs)\n",
    "encoding_2 = encode_layer2(encoding_1)\n",
    "the_code = coding_layer(encoding_2)\n",
    "\n",
    "# Decoder Layers\n",
    "#decode_layer1 = Dense(2 * encoding_dim, activation='tanh',name=\"decode_layer1\")\n",
    "#decode_layer2 = Dense(4 * encoding_dim, activation='tanh',name=\"decode_layer2\")\n",
    "#reconstruction_layer = Dense(input_dim, activation='tanh',name=\"reconstruction_layer\")\n",
    "decode_layer1 = DenseTied(coding_layer, activation='tanh',name=\"decode_layer1\")\n",
    "decode_layer2 = DenseTied(encode_layer2, activation='tanh',name=\"decode_layer2\")\n",
    "recon_layer = DenseTied(encode_layer1, activation='tanh',name=\"reconstruction_layer\")\n",
    "\n",
    "decoding_1 = decode_layer1(the_code)\n",
    "decoding_2 = decode_layer2(decoding_1)\n",
    "reconstruction = recon_layer(decoding_2)\n",
    "\n",
    "ae = Model(inputs=inputs, outputs=reconstruction)\n",
    "#monitor = EarlyStopping(monitor='loss', min_delta=0.0001, patience=5, verbose=1, mode='auto')\n",
    "ae.compile(optimizer='adam', loss='mse')\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "DEBUG = False\n",
    "\n",
    "class WeightHistory(keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        print(batch)\n",
    "        print('coding layer weights')\n",
    "        print(self.model.get_layer('coding_layer').get_weights())\n",
    "        print(self.model.get_layer('coding_layer').get_weights()[0].shape)\n",
    "        print('decoding layer weights')\n",
    "        print(np.transpose(self.model.get_layer('decode_layer1').get_weights()))\n",
    "        print(np.transpose(self.model.get_layer('decode_layer1').get_weights()[0]).shape)\n",
    "\n",
    "\n",
    "history = WeightHistory()\n",
    "\n",
    "if DEBUG:\n",
    "    callbacks.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.fit(x_train, x_train.toarray(), epochs=2, verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding_model = Model(inputs=ae.inputs, outputs=ae.get_layer(\"the_code\").output)\n",
    "coding_model = Model(inputs=inputs, outputs=the_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the embeddings in order to plot them later\n",
    "# serialize model to JSON\n",
    "model_json = coding_model.to_json()\n",
    "with open(\"coding_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "coding_model.save_weights(\"coding_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#save the adjacency matrix as well\n",
    "save_object(op_graph, 'adj_graph.pkl')\n",
    "print(\"Saved graph object to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
