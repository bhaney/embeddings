{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class MultiGraph:\n",
    "    def __init__(self):\n",
    "        self.n_nodes = 0\n",
    "        self.n_rels = 0\n",
    "        self.nodes = {}\n",
    "        self.rels = {}\n",
    "        self.node_labels = []\n",
    "        self.rel_labels = []\n",
    "        self.sparse_graph = {} #{relation: [row, col, data]}\n",
    "        self.rel_counter = Counter()\n",
    "    \n",
    "    def add_connection(self, connection):\n",
    "        # connection is (source, relation, target)\n",
    "        src,rel,targ = connection\n",
    "        #add new nodes and relations to dictionaries\n",
    "        if src not in self.nodes.keys():\n",
    "            self.nodes[src] = self.n_nodes\n",
    "            self.node_labels.append(src)\n",
    "            self.n_nodes += 1\n",
    "        if targ not in self.nodes.keys():\n",
    "            self.nodes[targ] = self.n_nodes\n",
    "            self.node_labels.append(targ)\n",
    "            self.n_nodes += 1\n",
    "        if rel not in self.rels.keys():\n",
    "            self.rels[rel] = self.n_rels\n",
    "            self.rel_labels.append(rel)\n",
    "            self.n_rels += 1\n",
    "            self.sparse_graph[self.rels[rel]] = [[],[],[]] #{relation: [row, col, data]}\n",
    "        #count number of relations\n",
    "        self.rel_counter.update({rel: 1})\n",
    "        # add new connection to graph\n",
    "        self.sparse_graph[self.rels[rel]][0].append(self.nodes[src])\n",
    "        self.sparse_graph[self.rels[rel]][1].append(self.nodes[targ])\n",
    "        self.sparse_graph[self.rels[rel]][2].append(1)\n",
    "    \n",
    "    def get_adjacency_matrix(self):\n",
    "        #iterleave all the columns from the individual adjacency matrices\n",
    "        #it is an out-going adjacency graph\n",
    "        full_matrix = [[],[],[]]\n",
    "        for k in range(self.n_rels):\n",
    "            full_matrix[0].extend(self.sparse_graph[k][0])\n",
    "            #shift the column index to fit the added relation \n",
    "            col_shift = [i*self.n_rels+k for i in self.sparse_graph[k][1]]\n",
    "            full_matrix[1].extend(col_shift)\n",
    "            full_matrix[2].extend(self.sparse_graph[k][2])\n",
    "        shape = (self.n_nodes,self.n_nodes*self.n_rels)\n",
    "        return csr_matrix((full_matrix[2], (full_matrix[0],full_matrix[1])), shape=shape, dtype=np.float32)\n",
    "    \n",
    "    def get_adjacency_matrix_k(self,k):\n",
    "        #it is an out-going adjacency graph of relation k\n",
    "        graph_k = self.sparse_graph[self.rels[k]]\n",
    "        shape = (self.n_nodes,self.n_nodes)\n",
    "        return csr_matrix((graph_k[2], (graph_k[0],graph_k[1])), shape=shape, dtype=np.float32)\n",
    "    \n",
    "    def get_node_label(self,index):\n",
    "        return self.node_labels[index]\n",
    "    \n",
    "    def get_relation_label(self,index):\n",
    "        return self.rel_labels[index]\n",
    "    \n",
    "    def get_relation_counter(self):\n",
    "        return self.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading relation 0...\n",
      "loading relation 1...\n",
      "loading relation 2...\n",
      "loading relation 3...\n",
      "loading relation 4...\n",
      "loading relation 5...\n",
      "loading relation 6...\n",
      "loading relation 7...\n",
      "loading relation 8...\n",
      "loading relation 9...\n",
      "loading relation 10...\n",
      "loading relation 11...\n",
      "loading relation 12...\n",
      "loading relation 13...\n",
      "loading relation 14...\n",
      "loading relation 15...\n",
      "loading relation 16...\n",
      "loading relation 17...\n",
      "loading relation 18...\n",
      "loading relation 19...\n",
      "loading relation 20...\n",
      "loading relation 21...\n",
      "loading relation 22...\n",
      "loading relation 23...\n",
      "loading relation 24...\n",
      "loading relation 25...\n",
      "loading relation 26...\n",
      "loading relation 27...\n",
      "loading relation 28...\n",
      "loading relation 29...\n",
      "loading relation 30...\n",
      "loading relation 31...\n",
      "loading relation 32...\n",
      "loading relation 33...\n",
      "loading relation 34...\n",
      "loading relation 35...\n",
      "loading relation 36...\n",
      "loading relation 37...\n",
      "loading relation 38...\n",
      "loading relation 39...\n",
      "loading relation 40...\n",
      "loading relation 41...\n",
      "loading relation 42...\n",
      "loading relation 43...\n",
      "loading relation 44...\n"
     ]
    }
   ],
   "source": [
    "#import csv\n",
    "import unicodecsv as csv\n",
    "\"\"\" EXAMPLE\n",
    "add,IS,operator\n",
    "subtract,IS,operator\n",
    "multiply,IS,operator\n",
    "divide,IS,operator\n",
    "open_closure,IS,operator\n",
    "close_closure,IS,operator\n",
    "\"\"\"\n",
    "op_graph = MultiGraph()\n",
    "#with open('operator_graph.csv', 'r') as csvfile:\n",
    "for i in range(45):\n",
    "    print('loading relation '+str(i)+'...')\n",
    "    with open('aifb_csv/aifb_relation_'+str(i)+'.csv', 'r') as csvfile:\n",
    "        graphreader = csv.reader(csvfile, delimiter=\",\")\n",
    "        for row in graphreader:\n",
    "            #print(row)\n",
    "            op_graph.add_connection(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of nodes', 8284)\n",
      "('number of relations', 45)\n",
      "relations:\n",
      "(u'ontology#number', 145)\n",
      "(u'ontology#isWorkedOnBy', 571)\n",
      "(u'ontology#worksAtProject', 200)\n",
      "(u'owl#allValuesFrom', 152)\n",
      "(u'ontology#dealtWithIn', 357)\n",
      "(u'owl#onProperty', 152)\n",
      "(u'ontology#type', 50)\n",
      "(u'ontology#author', 3986)\n",
      "(u'ontology#abstract', 534)\n",
      "(u'ontology#carriedOutBy', 79)\n",
      "(u'ontology#month', 759)\n",
      "(u'ontology#phone', 227)\n",
      "(u'22-rdf-syntax-ns#type', 4124)\n",
      "(u'ontology#address', 202)\n",
      "(u'ontology#note', 114)\n",
      "(u'ontology#publication', 4163)\n",
      "(u'ontology#financedBy', 65)\n",
      "(u'ontology#chapter', 15)\n",
      "(u'ontology#editor', 190)\n",
      "(u'ontology#pages', 548)\n",
      "(u'owl#inverseOf', 10)\n",
      "(u'ontology#projectInfo', 952)\n",
      "(u'type', 129)\n",
      "(u'ontology#edition', 12)\n",
      "(u'ontology#booktitle', 765)\n",
      "(u'ontology#isAbout', 2477)\n",
      "(u'ontology#finances', 68)\n",
      "(u'ontology#howpublished', 49)\n",
      "(u'ontology#member', 339)\n",
      "(u'ontology#hasProject', 952)\n",
      "(u'ontology#isbn', 16)\n",
      "(u'ontology#journal', 161)\n",
      "(u'ontology#year', 1227)\n",
      "(u'ontology#title', 1227)\n",
      "(u'ontology#fax', 227)\n",
      "(u'rdf-schema#range', 1)\n",
      "(u'ontology#homepage', 239)\n",
      "(u'ontology#carriesOut', 79)\n",
      "(u'ontology#photo', 148)\n",
      "(u'rdf-schema#subClassOf', 199)\n",
      "(u'ontology#head', 5)\n",
      "(u'ontology#volume', 311)\n",
      "(u'ontology#publishes', 1217)\n",
      "(u'ontology#name', 1302)\n",
      "(u'ontology#series', 298)\n"
     ]
    }
   ],
   "source": [
    "a_graph = op_graph.get_adjacency_matrix()\n",
    "print(\"number of nodes\",op_graph.n_nodes)\n",
    "print(\"number of relations\",op_graph.n_rels)\n",
    "print(\"relations:\")\n",
    "for k,v in op_graph.rel_counter.iteritems():\n",
    "    print(k.rsplit('/',1)[-1], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input dims:', (8284, 372780))\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x372780 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 18 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = a_graph\n",
    "print('input dims:',x_train.shape)\n",
    "print(type(x_train))\n",
    "sum(list(x_train[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 372780)            0         \n",
      "_________________________________________________________________\n",
      "encoding_1 (Dense)           (None, 512)               190863872 \n",
      "_________________________________________________________________\n",
      "encoding_2 (Dense)           (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "the_code (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "decoding_1 (Dense)           (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "decoding_2 (Dense)           (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "reconstruction (Dense)       (None, 372780)            95804460  \n",
      "=================================================================\n",
      "Total params: 287,029,932\n",
      "Trainable params: 287,029,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoding_dim = 128\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "inputs = Input(shape=(input_dim,))\n",
    "# Encoder Layers\n",
    "encoding_1 = Dense(4 * encoding_dim, activation='tanh',name=\"encoding_1\")(inputs)\n",
    "encoding_2 = Dense(2 * encoding_dim, activation='tanh',name=\"encoding_2\")(encoding_1)\n",
    "the_code = Dense(encoding_dim, activation='tanh',name=\"the_code\")(encoding_2)\n",
    "# Decoder Layers\n",
    "decoding_1 = Dense(4 * encoding_dim, activation='tanh',name=\"decoding_1\")(the_code)\n",
    "decoding_2 = Dense(2 * encoding_dim, activation='tanh',name=\"decoding_2\")(decoding_1)\n",
    "reconstruction = Dense(input_dim, activation='tanh',name=\"reconstruction\")(decoding_2)\n",
    "\n",
    "ae = Model(inputs=inputs, outputs=reconstruction)\n",
    "#monitor = EarlyStopping(monitor='loss', min_delta=0.0001, patience=5, verbose=1, mode='auto')\n",
    "ae.compile(optimizer='adam', loss='mse')\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "8284/8284 [==============================] - 547s 66ms/step - loss: 9.3240e-06\n",
      "Epoch 2/2\n",
      "8284/8284 [==============================] - 621s 75ms/step - loss: 9.2851e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1096e8890>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.fit(x_train, x_train.toarray(), epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding_model = Model(inputs=ae.inputs, outputs=ae.get_layer(\"the_code\").output)\n",
    "coding_model = Model(inputs=inputs, outputs=the_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#save the embeddings in order to plot them later\n",
    "# serialize model to JSON\n",
    "model_json = coding_model.to_json()\n",
    "with open(\"coding_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "coding_model.save_weights(\"coding_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
